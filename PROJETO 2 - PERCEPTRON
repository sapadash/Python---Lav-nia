"""cria classe MyPerceptron, um perceptron é um modelo que recebe dados e tenta
adivinhar a que grupo eles pertencem. o perceptron "aprende" ajustando seus pesos
até acertar o máximo possível"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

class myperceptron():
  def __init__(self, no_of_inputs, threshold=150, learning_rate=0.01):
    #inicializa o número de entradas(numero de caracteristicas das flores),
    #número de iterações e taxa de aprendizado
    self.threshold = threshold
    self.learning_rate = learning_rate
    #inicializa os pesos com zeros
    self.weights = np.zeros(no_of_inputs + 1) #[o +1 representa o bias, o peso
    #extra que sempre multiplica por 1

  def predict(self, inputs):
    inputs_w_bias = np.insert(inputs, 0, 1)
    #insere o bias no inicio do vetor (1, comprimento, largura)
    soma = np.dot(self.weights, inputs_w_bias)

    return 1 if soma > 0 else 0

  def train(self, training_inputs, labels):
    #training inputs= array com caracteristicas das flores. ex. [1.3,0.3],[1.5,0.5]... (+flores)
    #labels= array com as respostas certas (1=setosa, 0=não setosa)
    errors_history = []
    #treinar varias vezes
    for i in range(self.threshold):
      #para cada flor no zip de treino
      for inputs, label in zip(training_inputs, labels):
        #prever
        prediction = self.predict(inputs)
        #calculo do erro
        error = label - prediction
        #ajustar os pesos (caso de erro)
        if error !=0:
          #atualiza os pesos
          self.weights=self.weights + self.learning_rate * error * np.insert(inputs, 0, 1)
          #armazena o erro
          errors_history.append(error)
    return errors_history
    #salva o historico de erros

"""PERCEPTRON"""


# 1. CARREGAR OS DADOS

iris = load_iris()
print("=== PERCEPTRON 1 ===")
print("\nespécies: setosas e não setosas")  # nomes das espécies
print("características: comprimento da sépala (cm), largura da sépala (cm), comprimento da petala (cm) e largura da pétala (cm)")  # nomes das medidas

# 2. PREPARAR OS DADOS
# pegamos só comprimento e largura da pétala (índices 2 e 3)
x = iris.data[:, (2, 3)]  # características: [comprimento, largura]
# criamos os rótulos: 1 se for Setosa, 0 se não for
y = (iris.target == 0).astype(int)

print(f"\nprimeiras 5 flores:")
print("características:", x[:5])
print("é setosa?", y[:5])

# 3. DIVIDIR EM TREINO E TESTE
# 50% dos dados para treino, 50% para teste
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=0)

print(f"\ndivisão dos dados:")
print(f"treino: {len(x_train)} flores")
print(f"teste: {len(x_test)} flores")

# 4. CRIAR E TREINAR O PERCEPTRON
print("\n=== TREINANDO O PERCEPTRON ===")
perceptron = myperceptron(no_of_inputs=2, threshold=100, learning_rate=0.01)
errors = perceptron.train(x_train, y_train)

# 5. MOSTRAR RESULTADOS DO TREINO
print(f"\n=== PESOS APRENDIDOS ===")
print(f"bias (w0): {perceptron.weights[0]:.4f}  (tendência geral)")
print(f"peso para comprimento (w1): {perceptron.weights[1]:.4f}")
print(f"peso para largura (w2): {perceptron.weights[2]:.4f}")

# 6. TESTAR O PERCEPTRON
print("\n=== TESTANDO O PERCEPTRON ===")
correct = 0
total = len(x_test)

print("\nresultados do teste (primeiras 10 flores):")
for i, (inputs, true_label) in enumerate(zip(x_test[:10], y_test[:10])):
    prediction = perceptron.predict(inputs)
    is_correct = prediction == true_label

    if is_correct:
        correct += 1

    status = "S" if is_correct else "N"
    previsao = "setosa" if prediction == 1 else "não-Setosa"
    especie = "Setosa" if true_label == 1 else "não-Setosa"

    print(f"flor {i+1}: {inputs} cm | previsão: {previsao} {status}| verdade: {especie} ")

# calcular acurácia para todas as flores de teste
predictions = [perceptron.predict(x) for x in x_test]
correct = sum(p == t for p, t in zip(predictions, y_test))
accuracy = correct / len(y_test) * 100

print(f"\n=== RESULTADO FINAL ===")
print(f"acurácia no teste: {accuracy:.2f}% ({correct}/{len(y_test)} acertos)")

# 7. TENTAR NOVAMENTE

x = iris.data[:, (2, 3)]  # características: [comprimento, largura]
# criamos os rótulos: 1 se for Setosa, 0 se não for
y = (iris.target == 0).astype(int)

print("\n=== PERCEPTRON 2 ===")
print("\nprimeiras 5 flores:")
print("características:", x[:5])
print("é setosa?", y[:5])

# 70% dos dados para treino, 30% para teste
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)

print(f"\ndivisão dos dados:")
print(f"treino: {len(x_train)} flores")
print(f"teste: {len(x_test)} flores")

print("\n=== TREINANDO O PERCEPTRON ===")
perceptron = myperceptron(no_of_inputs=2, threshold=100, learning_rate=0.01)
errors = perceptron.train(x_train, y_train)

print(f"\n=== PESOS APRENDIDOS ===")
print(f"bias (w0): {perceptron.weights[0]:.4f}  (tendência geral)")
print(f"peso para comprimento (w1): {perceptron.weights[1]:.4f}")
print(f"peso para largura (w2): {perceptron.weights[2]:.4f}")

print("\n=== TESTANDO O PERCEPTRON ===")
correct = 0
total = len(x_test)

print("\nresultados do teste (primeiras 10 flores):")
for i, (inputs, true_label) in enumerate(zip(x_test[:10], y_test[:10])):
    prediction = perceptron.predict(inputs)
    is_correct = prediction == true_label

    if is_correct:
        correct += 1

    status = "S" if is_correct else "N"
    previsao = "setosa" if prediction == 1 else "não-setosa"
    especie = "setosa" if true_label == 1 else "não-setosa"

    print(f"flor {i+1}: {inputs} cm | previsão: {previsao} {status}| verdade: {especie} ")

# calcular acurácia para todas as flores de teste
predictions = [perceptron.predict(x) for x in x_test]
correct = sum(p == t for p, t in zip(predictions, y_test))
accuracy = correct / len(y_test) * 100

print(f"\n=== RESULTADO FINAL ===")
print(f"acurácia no teste: {accuracy:.2f}% ({correct}/{len(y_test)} acertos)")

"""COMPARAR COM SCIKIT-LEARN"""

from sklearn.linear_model import Perceptron as SKPerceptron

# cria e treina o perceptron do scikit-learn
sk_perceptron = SKPerceptron(max_iter=100, eta0=0.01, random_state=0)
sk_perceptron.fit(x_train, y_train)

# compara os resultados
my_accuracy = accuracy * 100  # do meu perceptron
sk_accuracy = sk_perceptron.score(x_test, y_test) * 100

print(f"\n=== COMPARAÇÃO COM SCIKIT-LEARN ===")
print(f"acurácia do meu Perceptron: {my_accuracy:.2f}%")
print(f"acurácia do scikit-Learn: {sk_accuracy:.2f}%")

# comparar previsões para uma flor específica
test_flower = [[1, 0.5]]
my_pred = perceptron.predict(test_flower[0])
sk_pred = sk_perceptron.predict(test_flower)[0]

print(f"\nprevisão para flor [1.0, 0.5]:")
print(f"meu perceptron: {my_pred} ({'setosa' if my_pred == 1 else 'não-setosa'})")
print(f"scikit-Learn: {sk_pred} ({'setosa' if sk_pred == 1 else 'não-setosa'})")

# GRAFICOS

print("\n=== GRÁFICO: REAL vs PREDICAO ===")

def plot_real_vs_predicted(x_test, y_test, predictions):
    """
    gráfico lado a lado: classificação real vs prevista
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))
    
    # cores baseadas nas classes
    colors_test = ['green' if y == 1 else 'purple' for y in y_test]
    colors_pred = ['green' if p == 1 else 'purple' for p in predictions]
    
    # gráfico da esquerda = real
    ax1.scatter(x_test[:, 0], x_test[:, 1], c=colors_test, alpha=0.7, s=15)
    ax1.set_title('label')
    ax1.set_xlabel('comprimento')
    ax1.set_ylabel('largura')
    
    # gráfico da direita: predito
    ax2.scatter(x_test[:, 0], x_test[:, 1], c=colors_pred, alpha=0.7, s=15)
    ax2.set_title('classificação')
    ax2.set_xlabel('comprimento')
    ax2.set_ylabel('largura')
    
    plt.tight_layout()
    plt.show()

plot_real_vs_predicted(x_test, y_test, predictions)

print("\n=== GRÁFICO: CLASSIFICAÇÃO vs LABEL ===")

def plot_class_vs_label(y_test, predictions):
    plt.figure(figsize=(10, 4))
    
    n = len(y_test)
    
    # plotar pontos
    plt.scatter(range(n), y_test, s=100, label='Real', 
                color='blue', marker='o', alpha=0.7)
    plt.scatter(range(n), predictions, s=100, label='Perceptron', 
                color='green', marker='s', alpha=0.7)
    
    # linhas vermelhas para erros
    for i in range(n):
        if y_test[i] != predictions[i]:
            plt.plot([i, i], [y_test[i], predictions[i]], 
                    'r-', linewidth=2, alpha=0.5)
    
    plt.xlabel('indice da flor')
    plt.ylabel('classe (0=não-setosa, 1=setosa)')
    plt.title('classificação real vs classificação do perceptron')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(-0.2, 1.2)
    
    plt.show()

plot_class_vs_label(y_test, predictions)


print("\n=== OUTRO EXEMPLO DE APLICAÇÃO ===")
print("""APROVADO vs REPROVADO:
   - Características: nota1, nota2, frequência
   - Output: 1=aprovado, 0=reprovado""")

print("\n=== QUANDO O PERCEPTRON FALHA ===")

print("1. só funciona com dados LINEARMENTE separáveis")
print("2. não resolve problemas complexos como XOR")
print("3. precisa de mais camadas para problemas reais")

# Testar com dados não-lineares
x_dificil = iris.data[50:, (2, 3)]  # Versicolor e Virginica
y_dificil = (iris.target[50:] == 1).astype(int)  # Versicolor=1, Virginica=0

perceptron2 = myperceptron(2, threshold=200, learning_rate=0.01)
perceptron2.train(x_dificil, y_dificil)

acertos = sum(perceptron2.predict(x) == y for x, y in zip(x_dificil, y_dificil))
total = len(y_dificil)

print(f"\nteste difícil (versicolor vs virginica):")
print(f"acertos: {acertos}/{total}")
print(f"acurácia: {acertos/total*100:.1f}% → BAIXA")


"""EXTRA"""

print("\n=== EXTRA ===")

# usar todas as 4 características (comprimento e largura da sépala e pétala)
x_all = iris.data  # todas as 4 colunas
y_all = (iris.target == 0).astype(int)

#dividir em treino e teste
x_train_all, x_test_all, y_train_all, y_test_all = train_test_split(x_all, y_all, test_size=0.3, random_state=0)

#criar e treinar perceptron com 4 entradas
perceptron_4d = myperceptron(no_of_inputs=4, threshold=100, learning_rate=0.01)
perceptron_4d.train(x_train_all, y_train_all)

#testar
predictions_4d = [perceptron_4d.predict(x) for x in x_test_all]
accuracy_4d = sum(p == t for p, t in zip(predictions_4d, y_test_all)) / len(y_test_all) * 100

print(f"treino com 4 características:")
print(f"acurácia: {accuracy_4d:.2f}%")
print(f"pesos aprendidos: {perceptron_4d.weights}")
print(f"comparação com 2 características: {accuracy:.2f}%")
